{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de apoio\n",
    "\n",
    "## Vamos criar algumas funções para não termos que reescrever códigos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "## FUNÇÕES DE APOIO ###\n",
    "#######################\n",
    "\n",
    "from numpy import absolute\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "\n",
    " # Imprime a média dos resultados obtidos por todos os modelos testados\n",
    "def print_results(prec, accur, mae, recall):\n",
    "    print('Precision: %.3f (%.3f)' % (mean(prec), std(prec))) #buscamos 1\n",
    "    print('Accuracy: %.3f (%.3f)' % (mean(accur), std(accur))) #buscamos 1\n",
    "    print('Recall: %.3f (%.3f)' % (mean(recall), std(recall))) #buscamos 1\n",
    "    print('MAE: %.3f (%.3f)' % (mean(absolute(mae)), std(absolute(mae)))) #buscamos o 0.0 de loss\n",
    "\n",
    "\n",
    "# Imprime um gráfico com a matriz de confusão\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, title=None):\n",
    "    cm_obj = ConfusionMatrixDisplay(cm, display_labels=['Ficou', 'Saiu'])\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    cm_obj.plot(ax=ax)\n",
    "    cm_obj.ax_.set(\n",
    "                    title='Matriz Confusão' if title == None else title, \n",
    "                    xlabel='Predito', \n",
    "                    ylabel='Atual')\n",
    "    \n",
    "\n",
    "#Faz os testes com modelos e imprime os resultados de forma padronizada\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def test_model(X, y, model, plot_cmatrix=True, print_cmatrix=False, print_subtitles=False, title=None):\n",
    "    # define the model cross-validation configuration\n",
    "    cv = StratifiedKFold(n_splits=8, random_state=1, shuffle=True)\n",
    "    scoring = ['accuracy', 'precision','neg_mean_absolute_error', 'recall']\n",
    "\n",
    "    # define the data preparation and modeling pipeline\n",
    "    pipeline = Pipeline(steps=[('m', model)])\n",
    "\n",
    "    #Calcula os scores do kfold\n",
    "    scores = cross_validate(pipeline, X, y, scoring=scoring, cv=cv, n_jobs=-1, return_estimator=True)\n",
    "\n",
    "    #Recupera os dados do cross_validate\n",
    "    prec = scores['test_precision']\n",
    "    accur = scores['test_accuracy']\n",
    "    mae = scores['test_neg_mean_absolute_error']\n",
    "    recall = scores['test_recall']\n",
    "\n",
    "    #Chama a função para imprimir os dados\n",
    "    print_results(prec, accur, mae, recall)\n",
    "\n",
    "    # Executa uma predição \"crossvalidada\"\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=cv)\n",
    "    # Recupera a matriz confusão da validação cruzada\n",
    "    cm = confusion_matrix(y_true=y, y_pred=y_pred)\n",
    "    \n",
    "    #Imprime o report do sklearn\n",
    "    print(classification_report(y, y_pred, zero_division=0))\n",
    "\n",
    "    #Imprime a legenda do que é apresentado no classification_report\n",
    "    if (print_subtitles):\n",
    "        print('Legenda:')\n",
    "        print('*Precisão é a capacidade de um classificador de não rotular uma instância positiva que na verdade é negativa (melhor 1)\\n\\tTP/(TP + FP)')\n",
    "        print('*Recall é a capacidade de um classificador de encontrar todas as instâncias positivas (melhor 1)\\n\\tTP/(TP + FN)')\n",
    "        print('*F1 = Percentual de positivos corretos (melhor 1)\\n\\tF1 Score = 2*(Recall * Precision) / (Recall + Precision)')\n",
    "        print('*Suporte é o número de ocorrências reais da classe no conjunto de dados especificado\\n')\n",
    "        print('*Macro avg é a média de precisão, recall e F1 de todas as classes\\n\\tmacro-avg = (precisão classe 0 + precisão classe 1)/2')\n",
    "        print('*weighted avg é a média ponderada da precisão, recall e F1 de todas as classes mescladas\\n\\tweighted average = (TP de 0 + TP de 1)/(totais das classes 0 + 1)\\n')\n",
    "\n",
    "\n",
    "    #Imprime a matriz confusão como gráfico\n",
    "    if(plot_cmatrix):\n",
    "        plot_confusion_matrix(cm, title)\n",
    "    \n",
    "    #Imprime a matriz confusão como texto\n",
    "    if(print_cmatrix):\n",
    "        print(cm)\n",
    "\n",
    "    # retorna os estimators treinados\n",
    "    return scores['estimator']\n",
    "\n",
    "\n",
    "\n",
    "# Função para transformar as colunas numéricas com MinMaxScaler e categóricas em OHE usando Pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "def transform_columns(numerical, categorical, X_data):\n",
    "    # Faz uma cópia do DataFrame para não alterar os dados originais\n",
    "    df = X_data.copy()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    # Coloca em escala os valores numericos usando Pandas (é do mesmo jeito que usando matrizes)\n",
    "    df[numerical] = scaler.fit_transform(df[numerical])\n",
    "\n",
    "    # Transforma as categoricas em OHE usando Pandas\n",
    "    df = pd.get_dummies(df, dtype='int', columns=categorical)\n",
    "    #Ajusta os nomes das colunas substituindo espaços por underscore\n",
    "    df.columns = df.columns.str.replace(' ', '_')  \n",
    "\n",
    "    return df \n",
    "\n",
    "\n",
    "# Função para retornar os nomes das colunas numéricas e categóricas a partir dos tipos de dados\n",
    "def get_columns_types(X):\n",
    "    numerical_ix = X.select_dtypes(include=['int64']).columns\n",
    "    categorical_ix = X.select_dtypes(include=['object', 'category']).columns #Você pode incluir outros tipos nessa lista\n",
    "    return numerical_ix, categorical_ix\n",
    "\n",
    "\n",
    "\n",
    "# Função que ordena e plota um gráfico com a importância das variáveis de forma ordenada\n",
    "def plot_sorted_importance(features, inportance):\n",
    "    #Cria um dict\n",
    "    out = {}\n",
    "    for i in range(len(features)):\n",
    "        out[features[i]] = inportance[i] \n",
    "    \n",
    "    #Ordena o dic\n",
    "    out = dict(sorted(out.items(), key=lambda item: item[1]))\n",
    "\n",
    "    # #Imprime a importancia de cada variável\n",
    "    # for k in out.keys():\n",
    "    #     print('Feature: %s, Score: %.5f' % (k,out[k]))\n",
    "\n",
    "    #Plota o gráfico de barras ordenado\n",
    "    plt.bar([k for k in out.keys()], [out[k] for k in out.keys()])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Função para avaliar os modelos com dados de validação\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, mean_absolute_error\n",
    "\n",
    "def validate_trained_models(estimators, X_valid, y_valid):\n",
    "    #cria as listas vazias\n",
    "    prec = []\n",
    "    acc = []\n",
    "    rec = []    \n",
    "    mae = []\n",
    "\n",
    "    # Percorre os estimators retornados pelo KFold\n",
    "    for pipe in estimators:\n",
    "        y_pred = pipe.named_steps['m'].predict(X_valid)\n",
    "        prec.append(precision_score(y_valid, y_pred, zero_division=0))\n",
    "        acc.append(accuracy_score(y_valid, y_pred))\n",
    "        rec.append(recall_score(y_valid, y_pred))\n",
    "        mae.append(mean_absolute_error(y_valid, y_pred))\n",
    "\n",
    "    # Chama a função para imprimir os resultados\n",
    "    print_results(prec, acc, mae, rec)\n",
    "\n",
    "    #Gera a matriz confusão com o último modelo utilizado pelo KFold e exibe o gráfico\n",
    "    cm = confusion_matrix(y_true=y_valid, y_pred=y_pred)\n",
    "    plot_confusion_matrix(cm, title='Valores último modelo do KFold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#carregando o csv em um DataFrame usando a biblioteca Pandas\n",
    "df = pd.read_csv('rh.csv')\n",
    "\n",
    "## Exclui colunas desnecessárias\n",
    "#-------------------------------\n",
    "# As que possuem valor único\n",
    "counts = df.nunique()\n",
    "to_del = [df.columns[i] for i,v in enumerate(counts) if v == 1]\n",
    "df.drop(to_del, axis=1, inplace=True)\n",
    "\n",
    "#Exclui as que não fazem sentido para o negócio: com valor único para cada linha como contadores, ordenadores, identificadores etc. \n",
    "df.drop('codigo', axis=1, inplace=True)\n",
    "#------------------------------\n",
    "\n",
    "# Separa o X y do dataframe\n",
    "X, y = df.drop('deixou_a_empresa', axis=1), df['deixou_a_empresa']\n",
    "\n",
    "# Converte o y em numérico 0 ou 1 (vou fazer com Pandas o mesmo que o LabelEncoder faz)\n",
    "y = y.map({'S':1, 'N':0})\n",
    "\n",
    "# Como já conhecemos o conteúdo de nosso dataset (aula anterior)\n",
    "# Vamos colocar em escala as colunas numéricas (MinMaxScaler) e transformar as categóricas em OHE (OneHotEncode)\n",
    "\n",
    "# Primeiro recuperamos os nomes das colunas numericas e categóricas\n",
    "numerical_ix, categorical_ix = get_columns_types(X)\n",
    "\n",
    "# Agora usando função que criamos, vamos transformar os dados\n",
    "X_matriz = transform_columns(numerical_ix, categorical_ix, X)\n",
    "X_matriz.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com nosso dataset preparado, vamos testar novamente o modelo de regressão logística\n",
    "\n",
    "#Aplicando Regressão Logística com o dataframe  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Usando nossa função pra testar modelos com KFold\n",
    "rls = test_model(X_matriz, \n",
    "           y,\n",
    "           LogisticRegression(),\n",
    "           print_cmatrix=True, \n",
    "           print_subtitles=True, \n",
    "           title='Regressão Logística')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando nossa função, vamos plotar a importancia das variáveis\n",
    "plot_sorted_importance(X_matriz.columns, rls[0].named_steps['m'].coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Live - Modelos e transformações (Continuação)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando outros modelos nos mesmos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando RandomForest no mesmo dataframe para avaliar o modelo com os mesmos dados\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Usando nossa função pra testar modelos com KFold\n",
    "rfs = test_model(X_matriz, \n",
    "           y,\n",
    "           RandomForestClassifier(),\n",
    "           title='Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# Criando uma função para permitir os testes com SVM e KFold\n",
    "def test_svms(X, y):\n",
    "\n",
    "    # Vamos implementar vários parâmetros pra ver qual fica melhor\n",
    "    models = (\n",
    "        SVC(kernel=\"linear\"),\n",
    "        LinearSVC(max_iter=10000, dual=\"auto\"),\n",
    "        SVC(kernel=\"rbf\", gamma=0.7),\n",
    "        SVC(kernel=\"poly\", degree=3, gamma=\"auto\"),\n",
    "    )\n",
    "\n",
    "    titles = (\n",
    "        \"SVC with linear kernel\",\n",
    "        \"LinearSVC (linear kernel)\",\n",
    "        \"SVC with RBF kernel\",\n",
    "        \"SVC with polynomial (degree 3) kernel\",\n",
    "    )\n",
    "\n",
    "    estimators = []\n",
    "\n",
    "    # Realizando o teste para cada modelo\n",
    "    for t, model in zip(titles, models):\n",
    "        print(t)\n",
    "        # Recupero a lista de estimadores treinados\n",
    "        estimators.append(test_model(X, y, model, title=t))\n",
    "        print(\"\")\n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamo a função para testar os svms com o dataframe\n",
    "_ = test_svms(X_matriz, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "\n",
    "Nosso dataframe está desbalanceado. Alguns modelos são sensíveis a esse tipo de situação, porém outros ainda podem funcionar bem.\n",
    "\n",
    "Nessa parte será necessário usar o `train_test_split` para separarmos um pacote de validação do modelo. O pacote de validação deve manter a proporção original de ocorrências para verificarmos se o novo viés afetou de sobremaneira o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Retira uma parte dos dados para validação - com a configuracão original\n",
    "X_rus, X_valid, y_rus, y_valid = train_test_split(X_matriz, y, test_size=0.20, random_state=33, stratify=y)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "\n",
    "# Retira uma amostra randomica dos dados equilibrando x e y\n",
    "X_res, y_res = rus.fit_resample(X_rus, y_rus)\n",
    "\n",
    "print('Proporção antes')\n",
    "print(y_rus.value_counts(), end='\\n\\n')\n",
    "\n",
    "print('Nova proporção')\n",
    "print(y_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos aplicar nos modelos e validar - Regressão Logística\n",
    "lrs = test_model(X_res, y_res, LogisticRegression())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa os modelos gerados com os dados nas proporçoes reais que separamos para validação\n",
    "validate_trained_models(lrs, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando Random Forest balanceada\n",
    "print(\"Resultado do Treino com dados balanceados\")\n",
    "rf = test_model(X_res, y_res, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Validando Random Forest\n",
    "print(\"Resultado da Validação - Proporção original\")\n",
    "validate_trained_models(rf, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando svms balanceados\n",
    "print(\"Resultado do Treino com dados balanceados\")\n",
    "svms = test_svms(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Validando os svms\n",
    "print(\"Resultado da Validação - Proporção original\")\n",
    "\n",
    "# Percorre os estimadores e faz o teste de validação\n",
    "for i, estimators in enumerate(svms):\n",
    "    print(f'Modelo {i}' )\n",
    "    validate_trained_models(estimators, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecionando as variáveis mais importantes\n",
    "\n",
    "Nem sempre \"`mais é melhor`\" e muitas vezes variáveis redundantes podem gerar viézes que prejudicam os modelos. Portanto, nesse tópico vamos falar sobre seleção de variáveis pela importância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizaremos RFE para selecionar as variaveis mais importantes\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Aqui estamos imformando o número de variáveis que queremos utilizar\n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=10)\n",
    "\n",
    "rfe = rfe.fit(X_matriz, y)\n",
    "\n",
    "#Colunas selecionadas\n",
    "sel_cols = X_matriz.columns[rfe.support_]\n",
    "print(sel_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando as 10 colunas mais importantes como filtro, vamos testar o modelo de Regressao Logística!\n",
    "\n",
    "_ = test_model(X_matriz[sel_cols], y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outra opção de utilização, é deixarmos o algoritmo selecionar automaticamente a quantidade ideal de \n",
    "#colunas para o modelo\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Vamos criar uma função \n",
    "def get_rfe_cols(model):\n",
    "    rfe = RFECV(estimator=model)\n",
    "\n",
    "    rfe = rfe.fit(X_matriz, y)\n",
    "\n",
    "    #Colunas selecionadas\n",
    "    sel_cols = X_matriz.columns[rfe.support_]\n",
    "    print(sel_cols)\n",
    "    print(\"Quantidade selecionada: \" + str(len(sel_cols)), end=\"\\n\\n\")\n",
    "    return sel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas mais importantes usando o modelo de Regressão Logística\n",
    "sel_cols = get_rfe_cols(LogisticRegression())\n",
    "\n",
    "_ = test_model(X_matriz[sel_cols], y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando estimator em árvore\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Chama a nossa função passando um estimador em forma de árvore!\n",
    "sel_cols = get_rfe_cols(DecisionTreeClassifier())\n",
    "\n",
    "#Testa o resultado com Random Forest\n",
    "_ = test_model(X_matriz[sel_cols], y, RandomForestClassifier())\n",
    "\n",
    "# Rode várias vezes e veja que cada tentativa pode gerar um resultado diferente!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extratificação de variáveis - Variáveis numéricas em categóricas\n",
    "\n",
    "Esse método deve ser usado somente quando existem outliers nos dados, distribuições multimodais, distribuições altamente exponenciais e outros casos que fogem muito da distribuição de probabilidade padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando pandas.cut\n",
    "\n",
    "# Copiando nosso dataframe original\n",
    "X_extrat = X.copy()\n",
    "\n",
    "classes = [0, 5000, 10000, 15000, 100000] #criando as classes\n",
    "labels = ['até 5 mil', '5 a 10 mil', '10 a 15 mil', '+ de 15 mil'] #criando os labels\n",
    "\n",
    "X_extrat['salario'] = pd.cut(X_extrat['salario'], classes, labels=labels)\n",
    "X_extrat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos testar os resultados com a coluna salário em formato de categorias!\n",
    "# Separo as columnas para transformacao\n",
    "numerical_ix, categorical_ix = get_columns_types(X_extrat)\n",
    "\n",
    "print(numerical_ix, categorical_ix)\n",
    "\n",
    "# Transforma o dataframe para utilização nos modelos - chamamos nossa função\n",
    "X_test = transform_columns(numerical_ix, categorical_ix, X_extrat)\n",
    "\n",
    "# Listamos como ficou!\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a função de teste, vejamos como fica aplicando Regressão Logística!\n",
    "_ = test_model(X_test, y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a função de teste, vejamos como fica aplicando Random Forest!\n",
    "_ = test_model(X_test, y, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos também podemos extratificar colunas numéricas que são ordinais \n",
    "# para testar a influência delas nos modelos\n",
    "\n",
    "# Convertemos o tipo da coluna de numérica para categórica (texto)\n",
    "X_extrat['escolaridade'] = X_extrat['escolaridade'].apply(str)\n",
    "\n",
    "X_extrat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repito os procedimentos usando nossas funcoes!!\n",
    "\n",
    "#Recupero minhas colunas e transformo\n",
    "numerical_ix, categorical_ix = get_columns_types(X_extrat)\n",
    "X_test = transform_columns(numerical_ix, categorical_ix, X_extrat)\n",
    "\n",
    "# Listamos como ficou!\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a função de teste, vejamos como fica aplicando Random Forest!\n",
    "_ = test_model(X_test, y, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a função de teste, vejamos como fica aplicando Regressão Logística!\n",
    "_ = test_model(X_test, y, LogisticRegression())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
